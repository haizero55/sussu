# sussu(rro): CLI educacional com OpenAI Whisper

> Ferramenta de linha de comando focada em educa√ß√£o e IA offline.
> Usa o poder do Whisper da OpenAI pra transcrever √°udios e v√≠deos de forma simples.

Ao rodar este projeto, uma das primeiras coisas que voc√™ vai querer fazer √© usar o
comando `whisper` para fazer a transcri√ß√£o inicial de algum v√≠deo ou √°udio. Essa transcri√ß√£o √© um √≥timo jeito de ver na pr√°tica como o Whisper trabalha e o que esperar dos resultados.

- [Reposit√≥rio oficial do `whisper`](https://github.com/openai/whisper)

Por isso, vamos come√ßar pela **instala√ß√£o** do projeto, o que vai disponibilizar os comandos `sussu` e `whisper` no terminal.

## Instala√ß√£o do `sussu`

Este projeto usa o `Python 3.11.9` por quest√µes de compatibilidade com o Whisper. Evite alterar essa vers√£o caso n√£o saiba o que est√° fazendo, porque eu **j√° testei tudo para voc√™**.

Al√©m disso, este projeto tamb√©m usa o [uv](https://docs.astral.sh/uv/) no gerenciamento geral (pacotes, vers√£o do Python, etc).

```sh
uv sync  # √© s√≥ isso mesmo üòÖ
```

`uv sync` √© suficiente para:

- Baixar e instalar o `python 3.11.9`
- Criar o ambiente virtual em `.venv`
- Instalar os pacotes necess√°rios
- Buildar o `whisper` e o `sussu`

---

## `ffmpeg`

√â necess√°rio ter o [`ffmpeg`](https://ffmpeg.org/), que √© um pacote de software open source que cont√©m uma cole√ß√£o de ferramentas e bibliotecas para lidar com arquivos multim√≠dia, principalmente √°udio e v√≠deo. O `whisper` trabalha com transcri√ß√£o de arquivos de √°udio, mas o `ffmpeg` permite que voc√™ n√£o tenha que converter seus v√≠deos em √°udio para fazer a transcri√ß√£o.

Para instalar o ffmpeg no seu sistema use um dos comandos abaixo. Isso veio diretamente do [reposit√≥rio oficial do `whisper`](https://github.com/openai/whisper):

```sh
# no Ubuntu ou Debian
sudo apt update && sudo apt install ffmpeg

# no Arch Linux
sudo pacman -S ffmpeg

# no MacOS com Homebrew (https://brew.sh/)
brew install ffmpeg

# no Windows com Chocolatey (https://chocolatey.org/)
choco install ffmpeg

# no Windows usando Scoop (https://scoop.sh/)
scoop install ffmpeg

# Adicional
# no Windows usando winget (https://winstall.app/apps/Gyan.FFmpeg)
winget install --id=Gyan.FFmpeg  -e
```

**Observa√ß√£o:** os √∫nicos comandos que testei da lista acima foram do MacOS e Ubuntu. Aprovados ‚úÖ!

---

## Rodando pela primeira vez

Para testar se tudo funcionou perfeitamente voc√™ pode tanto **ativar o ambiente virtual** quanto usar **`uv run`**. Teste com `whisper -h`. Isso deve mostrar a `help` completa do `whisper`. Exemplos:

```sh
uv run whisper -h
# Ou se estiver com o ambiente virtual ativo
whisper -h
```

**Observa√ß√£o:** alguns editores como VS Code ou Zed, ativam seu ambiente virtual automaticamente ao abrir uma nova inst√¢ncia do terminal se tudo estiver configurado corretamente, basta sair (`exit`) e abrir novamente o terminal.

---

## `whisper -h`: entendendo alguns argumentos importantes

Ao digitar `whisper -h` ou `whisper --help`, voc√™ pode se assustar com a quantidade de argumentos que est√£o ali, dispon√≠veis para uso. Claro que voc√™ n√£o precisa saber o que cada um deles faz, na verdade, a maioria dos argumentos tem valores padr√£o que j√° funcionam perfeitamente. Mas, caso queira personalizar um pouco o comportamente, vamos analisar alguns deles.

O `whisper` usa o `argparse` do Python para criar essa `help` maravilhosa. Caso queira aprender mais sobre isso, assista meu v√≠deo:

- [Python e argparse: Do Zero a uma CLI Profissional (Projeto Real na Pr√°tica)](https://www.youtube.com/watch?v=Ad6934NXn4A)

---

### Argumentos essenciais do `whisper`

**`--model MODEL`:** define qual o modelo ser√° utilizado na transcri√ß√£o do √°udio. √â opcional, e o valor padr√£o √© `turbo`. Este model funciona muito bem, √© r√°pido e multil√≠ngue, mas requer cerca de **6GB de VRAM** para funcionar.

Talvez voc√™ queira usar outros modelos que usam mais ou menos recursos do seu hardware, ou que possuem mais ou menos par√¢metros (como `base`, `small`, `medium`, etc).

Abaixo os modelos dispon√≠veis:

- **`tiny`:** 39M, `tiny.en` e `tiny`, VRAM ~1 GB
- **`base`:** 74M, `base.en` e `base`, VRAM ~1 GB
- **`small`:** 244M, `small.en` e `small`, VRAM ~2 GB
- **`medium`:** 769M, `medium.en` e `medium`, VRAM ~5 GB
- **`large`:** 1550M, `large`, `large-v2` e `large-v3`, VRAM ~10 GB
- **`turbo`:** 809M, `turbo`, VRAM ~6 GB

**VRAM** √© um tipo especializado de mem√≥ria RAM usada pelas placas de v√≠deo (GPUs).
Se o seu computador compartilha a RAM com a GPU, como acontece nos Macs com chip Apple Silicon (M1, M2, M3 e posteriores), voc√™ conseguir√° usar os modelos do Whisper **mesmo sem uma placa de v√≠deo dedicada**.

Nesse caso, o fator limitador passa a ser a **quantidade total de mem√≥ria dispon√≠vel no sistema**.
Por exemplo: se voc√™ tem apenas 8GB de RAM, o ideal √© testar os modelos `tiny`, `base` ou `small`.

A partir do modelo `medium`, √© bem prov√°vel que voc√™ perceba uma **queda absurda no desempenho geral da m√°quina**, j√° que a mem√≥ria ser√° completamente consumida.

---
