# sussu(rro): CLI educacional com OpenAI Whisper

> Ferramenta de linha de comando focada em educa√ß√£o e IA offline.
> Usa o poder do Whisper da OpenAI para transcrever √°udios e v√≠deos de forma simples.

Ao rodar este projeto, uma das primeiras coisas que voc√™ vai querer fazer √© usar o comando `whisper` para fazer a transcri√ß√£o inicial de algum v√≠deo ou √°udio. Essa transcri√ß√£o √© um √≥timo jeito de ver na pr√°tica como o **Whisper** trabalha e o que esperar dos resultados.

- [Reposit√≥rio oficial do `whisper`](https://github.com/openai/whisper)

Por isso, vamos come√ßar pela **instala√ß√£o** do projeto, o que vai disponibilizar os comandos `sussu` e `whisper` no terminal.

## Instala√ß√£o do `sussu`

Se voc√™ encontrar alguma dificuldade com o ambiente, recomendo meu tutorial completo:

- [Ambiente Python Moderno 2025: UV, Ruff, Pyright, pyproject.toml e VS Code](https://www.youtube.com/watch?v=HuAc85cLRx0)

Este projeto utiliza o **Python 3.11.9** por quest√µes de compatibilidade com o **Whisper**. Evite alterar essa vers√£o se n√£o souber o que est√° fazendo, pois **eu j√° testei tudo para voc√™**.

Al√©m disso, este projeto usa o [`uv`](https://docs.astral.sh/uv/) para o gerenciamento geral (pacotes, vers√£o do Python, etc.).

Para instalar tudo, basta rodar o comando:

```sh
uv sync  # √© s√≥ isso mesmo üòÖ
```

`uv sync` √© suficiente para:

- Baixar e instalar o `python 3.11.9`
- Criar o ambiente virtual em `.venv`
- Instalar os pacotes necess√°rios
- Buildar o `whisper` e o `sussu`

---

## `ffmpeg`

Voc√™ tamb√©m precisar√° ter o **`ffmpeg`** instalado. Ele √© um software de c√≥digo aberto com v√°rias ferramentas e bibliotecas para trabalhar com arquivos multim√≠dia, especialmente √°udio e v√≠deo. Embora o `whisper` foque na transcri√ß√£o de √°udio, o `ffmpeg` √© quem permite que voc√™ transcreva seus v√≠deos diretamente, sem precisar convert√™-los para √°udio antes.

Para instalar o `ffmpeg` no seu sistema, voc√™ pode usar um dos comandos abaixo. Eles foram retirados diretamente do [reposit√≥rio oficial do `whisper`](https://github.com/openai/whisper):

```bash
# No Ubuntu ou Debian
sudo apt update && sudo apt install ffmpeg

# No Arch Linux
sudo pacman -S ffmpeg

# No macOS com Homebrew (https://brew.sh/)
brew install ffmpeg

# No Windows com Chocolatey (https://chocolatey.org/)
choco install ffmpeg

# No Windows usando Scoop (https://scoop.sh/)
scoop install ffmpeg

# Adicional: No Windows usando winget (https://winstall.app/apps/Gyan.FFmpeg)
winget install --id=Gyan.FFmpeg -e
```

**Observa√ß√£o:** Dos comandos listados, os √∫nicos que testei e aprovei (‚úÖ) foram os para **macOS** e **Ubuntu**.

---

## Rodando pela Primeira Vez

Para verificar se tudo foi instalado corretamente, voc√™ tem duas op√ß√µes: **ativar o ambiente virtual** ou usar o comando **`uv run`**. Sugiro que voc√™ teste com `whisper -h`. Esse comando deve exibir a ajuda completa do `whisper`, indicando que ele est√° funcionando. Veja os exemplos:

```bash
uv run whisper -h
# Ou, se voc√™ j√° ativou o ambiente virtual
whisper -h
```

**Observa√ß√£o:** Editores de c√≥digo como **VS Code** ou **Zed** podem ativar o ambiente virtual automaticamente ao abrir um novo terminal, desde que estejam configurados corretamente. Se for o seu caso, basta fechar e abrir o terminal novamente para que as mudan√ßas fa√ßam efeito.

---

## `whisper -h`: Entendendo Alguns Argumentos Importantes

Ao digitar `whisper -h` ou `whisper --help`, voc√™ pode se surpreender com a quantidade de argumentos dispon√≠veis. Mas n√£o se preocupe! Voc√™ n√£o precisa saber o que cada um deles faz. Na verdade, a maioria dos argumentos j√° vem com valores padr√£o que funcionam perfeitamente. No entanto, se voc√™ quiser personalizar um pouco o comportamento da ferramenta, vamos analisar alguns dos mais importantes.

O `whisper` utiliza a biblioteca `argparse` do Python para gerar essa documenta√ß√£o de ajuda (`help`) completa e bem organizada. Se voc√™ tiver interesse em aprender mais sobre como criar interfaces de linha de comando profissionais com Python, confira meu v√≠deo:

- [Python e argparse: Do Zero a uma CLI Profissional (Projeto Real na Pr√°tica)](https://www.youtube.com/watch?v=Ad6934NXn4A)

---

### Argumentos Essenciais do `whisper`

Vamos come√ßar com os argumentos que voc√™ usar√° com mais frequ√™ncia:

**`audio`**: Este √© o **argumento posicional** principal. Ele representa o caminho completo (localiza√ß√£o) do arquivo de √°udio ou v√≠deo que voc√™ quer transcrever.

**Exemplo:**

```bash
whisper /caminho/do/seu/arquivo.mp4
```

No exemplo acima, voc√™ notou que especificamos apenas o caminho do arquivo de v√≠deo. Nas pr√≥ximas se√ß√µes, vou detalhar as op√ß√µes que mais utilizo para personalizar a transcri√ß√£o.

---

**`--model MODEL`**: Este argumento serve para **definir qual modelo ser√° usado na transcri√ß√£o** do seu √°udio ou v√≠deo. Ele √© opcional, e o valor padr√£o √© `turbo`. O modelo `turbo` √© excelente: r√°pido e multil√≠ngue, mas requer cerca de **6GB de VRAM** para rodar.

Talvez voc√™ queira usar outros modelos que exigem mais ou menos recursos do seu hardware, ou que possuem mais ou menos par√¢metros (como `base`, `small`, `medium`, etc.).

Aqui est√£o os modelos dispon√≠veis e seus requisitos aproximados de VRAM:

- **`tiny`**: 39M par√¢metros, `tiny.en` e `tiny`, VRAM ~1 GB
- **`base`**: 74M par√¢metros, `base.en` e `base`, VRAM ~1 GB
- **`small`**: 244M par√¢metros, `small.en` e `small`, VRAM ~2 GB
- **`medium`**: 769M par√¢metros, `medium.en` e `medium`, VRAM ~5 GB
- **`large`**: 1550M par√¢metros, `large`, `large-v2` e `large-v3`, VRAM ~10 GB
- **`turbo`**: 809M par√¢metros, `turbo`, VRAM ~6 GB

**VRAM** √© um tipo de mem√≥ria RAM especializada que as placas de v√≠deo (GPUs) usam. Mas n√£o se preocupe se voc√™ n√£o tiver uma placa de v√≠deo dedicada! Se seu computador compartilha a RAM com a GPU, o que acontece em Macs com chips Apple Silicon (M1, M2, M3 e posteriores), por exemplo, voc√™ conseguir√° usar os modelos do Whisper normalmente.

Nesses casos, o que realmente limita √© a **quantidade total de mem√≥ria RAM dispon√≠vel no seu sistema**. Por exemplo: se voc√™ tem apenas 8GB de RAM, o ideal √© testar os modelos `tiny`, `base` ou `small`.

A partir do modelo `medium`, √© bem prov√°vel que voc√™ perceba uma **queda dr√°stica no desempenho geral da sua m√°quina**, j√° que a mem√≥ria ser√° completamente consumida.

**Exemplo:**

```bash
whisper /caminho/do/seu/arquivo.mp4 --model large-v2
```

---

**`--device DEVICE`**: Este argumento √© para voc√™ que possui uma **placa de v√≠deo NVIDIA com drivers CUDA** e uma vers√£o compat√≠vel com o PyTorch. Se for o seu caso, vale a pena usar `--device cuda` para aproveitar o processamento da GPU. Caso contr√°rio, n√£o se preocupe em alterar esta op√ß√£o, o padr√£o √© `cpu` (processamento pela CPU) e funcionar√° perfeitamente.

**Exemplo:**

```bash
whisper /caminho/do/seu/arquivo.mp4 --model large-v2 --device cpu
```

---

**`--output_dir` ou `-o`**: Define o **caminho da pasta onde as transcri√ß√µes ser√£o salvas**. Por padr√£o, os arquivos ser√£o salvos na raiz do projeto (`.`).

**`--output_format` ou `-f`**: Permite que voc√™ escolha o **formato da transcri√ß√£o ou legenda** gerada. As op√ß√µes dispon√≠veis s√£o: `txt`, `vtt`, `srt`, `tsv`, `json` e `all` (que gera todos os formatos). O padr√£o √© `all`.


**Exemplo:**

O arquivo de sa√≠da ser√° `srt` (SubRip) na pasta indicada em `-o`. Essa pasta ser√° criada caso n√£o exista.

```bash
whisper /caminho/do/seu/arquivo.mp4 --model turbo -o caminho/da/pasta_de_saida -f srt
```

---

**`--task`**: Com este argumento, voc√™ pode escolher entre **transcrever o √°udio** no idioma original ou **traduzir para o ingl√™s**. As op√ß√µes s√£o `transcribe` (o padr√£o, que transcreve no idioma falado no √°udio) ou `translate` (que traduz o conte√∫do para o ingl√™s).

**Exemplo:**

```bash
whisper /caminho/do/seu/arquivo.mp4 --model turbo --task transcribe
```

---

**`--language`**: Este argumento permite que voc√™ **especifique o idioma falado no √°udio ou v√≠deo**. Existem muitas op√ß√µes de idiomas dispon√≠veis. Se voc√™ n√£o informar esse argumento, o `whisper` √© inteligente o suficiente para detectar automaticamente o idioma do conte√∫do.

Forma curta (language code):

```python
["af", "am", "ar", "as", "az", "ba", "be", "bg", "bn", "bo", "br", "bs", "ca",
"cs", "cy", "da", "de", "el", "en", "es", "et", "eu", "fa", "fi", "fo", "fr",
"gl", "gu", "ha", "haw", "he", "hi", "hr", "ht", "hu", "hy", "id", "is", "it",
"ja", "jw", "ka", "kk", "km", "kn", "ko", "la", "lb", "ln", "lo", "lt", "lv",
"mg", "mi", "mk", "ml", "mn", "mr", "ms", "mt", "my", "ne", "nl", "nn", "no",
"oc", "pa", "pl", "ps", "pt", "ro", "ru", "sa", "sd", "si", "sk", "sl", "sn",
"so", "sq", "sr", "su", "sv", "sw", "ta", "te", "tg", "th", "tk", "tl", "tr",
"tt", "uk", "ur", "uz", "vi", "yi", "yo", "yue", "", "zh"]
```

- Exemplo para portugu√™s do Brasil: `--language pt`

Forma longa (language name):

```python
["Afrikaans", "Albanian", "Amharic", "Arabic", "Armenian", "Assamese",
"Azerbaijani", "Bashkir", "Basque", "Belarusian", "Bengali", "Bosnian",
"Breton", "Bulgarian", "Burmese", "Cantonese", "Castilian", "Catalan",
"Chinese", "Croatian", "Czech", "Danish", "Dutch", "English", "Estonian",
"Faroese", "Finnish", "Flemish", "French", "Galician", "Georgian", "German",
"Greek", "Gujarati", "Haitian", "Haitian Creole", "Hausa", "Hawaiian", "Hebrew",
"Hindi", "Hungarian", "Icelandic", "Indonesian", "Italian", "Japanese",
"Javanese", "Kannada", "Kazakh", "Khmer", "Korean", "Lao", "Latin", "Latvian",
"Letzeburgesch", "Lingala", "Lithuanian", "Luxembourgish", "Macedonian",
"Malagasy", "Malay", "Malayalam", "Maltese", "Mandarin", "Maori", "Marathi",
"Moldavian", "Moldovan", "Mongolian", "Myanmar", "Nepali", "Norwegian",
"Nynorsk", "Occitan", "Panjabi", "Pashto", "Persian", "Polish", "Portuguese",
"Punjabi", "Pushto", "Romanian", "Russian", "Sanskrit", "Serbian", "Shona",
"Sindhi", "Sinhala", "Sinhalese", "Slovak", "Slovenian", "Somali", "Spanish",
"Sundanese", "Swahili", "Swedish", "Tagalog", "Tajik", "Tamil", "Tatar",
"Telugu", "Thai", "Tibetan", "Turkish","Turkmen", "Ukrainian", "Urdu", "Uzbek",
"Valencian", "Vietnamese", "Welsh", "Yiddish", "Yoruba"]
```

- Exemplo para portugu√™s do Brasil: `--language Portuguese`

Se precisar de um dicion√°rio completo com todos os idiomas e seus c√≥digos, ele est√° dispon√≠vel em `whisper.tokenizer.LANGUAGES` dentro do c√≥digo do `whisper`.


**Exemplo:**

```bash
# Para o comando ficar menor, vou manter tudo padr√£o
# model turbo (padr√£o)
# task transcribe (padr√£o)
# etc...
# Idioma falado no v√≠deo "Portugu√™s"
whisper /caminho/do/seu/arquivo.mp4 --language pt
```


---

**`--temperature`:** controla a "criatividade" do modelo. Vai de `0.0` a `1.0`. Quanto mais alto, mais liberdade o modelo tem pra decidir os pr√≥ximos tokens. Esse par√¢metro interage com `--beam_size`, `--patience` e `--best_of`.

**`--beam_size`:** n√∫mero de hip√≥teses que o modelo mant√©m em paralelo. Pensa como se ele testasse v√°rios caminhos ao mesmo tempo e no fim escolhesse o melhor. O padr√£o √© `5` e **s√≥ funciona se `--temperature == 0.0`**.

**`--patience`:** fator de toler√¢ncia que faz o modelo continuar explorando novas hip√≥teses mesmo depois de achar uma aceit√°vel. Requer `--temperature == 0.0` e `--beam_size > 1`.

**`--best_of`:** n√∫mero de amostras diferentes geradas antes de escolher a melhor. Funciona apenas quando `--temperature > 0.0`.

**Cola r√°pida:**

```
- temperature > 0 ‚Üí usa sampling
  ‚úÖ --best_of 5 (5 amostras)
  üî¥ --beam_size (ignorado)
  üî¥ --patience (ignorado)

- temperature == 0 ‚Üí usa beam search
  ‚úÖ --beam_size 5 (5 hip√≥teses)
  ‚úÖ --patience 2 (2 x 5 = 10 hip√≥teses)
  üî¥ --best_of (ignorado)

- temperature == 0 ‚Üí greedy
  ‚úÖ --beam_size 1 (1 hip√≥tese)
  üî¥ --patience (n√£o faz diferen√ßa)
  üî¥ --best_of (ignorado)
```

**Importante:** Quanto maiores os valores de `--beam_size`, `--patience` e `--best_of`, mais lento e "indeciso" o modelo tende a ficar. Isso acontece porque ele precisa gerar mais hip√≥teses ou amostras e, em seguida, tomar uma decis√£o entre elas. Fa√ßa testes r√°pidos para confirmar esse comportamento.

**Observa√ß√£o sincera:**

Na pr√°tica, o modelo vai responder como foi treinado, independente do seu capricho nas configs. Trocar `temperature`, `beam_size`, `patience` e afins pode virar desperd√≠cio de tempo.

**Recomenda√ß√£o direta:** s√≥ mexa nessas op√ß√µes se:

- o modelo come√ßar a repetir palavras (loop)
- estiver errando demais em blocos grandes

Se for s√≥ por causa de uma ou duas palavras... aceita e segue. Ou ent√£o faz igual eu: **testa tudo por uma semana e conclui que o padr√£o j√° era bom** üòÖ

**Exemplo:**

O arquivo de sa√≠da ser√° `srt` (SubRip) na pasta indicada em `-o`. Essa pasta ser√° criada caso n√£o exista.

```bash
# Greedy: Mais r√°pido, mas pode errar mais por considerar apenas uma hip√≥tese por vez.
whisper /caminho/do/seu/arquivo.mp4 --temperature 0.0 --beam_size 1

# Beam Search: Utiliza 3 hip√≥teses em paralelo.
# O 'patience' padr√£o √© 1.
whisper /caminho/do/seu/arquivo.mp4 --temperature 0.0 --beam_size 3

# Sampling: Gera 5 amostras diferentes para escolher a melhor.
whisper /caminho/do/seu/arquivo.mp4 --temperature 0.7 --best_of 5
```

**`--temperature_increment_on_fallback`**: Este argumento permite que voc√™ **aumente a temperatura do modelo em casos de falha na transcri√ß√£o**. Se o modelo encontrar dificuldades na temperatura `0.0`, ele far√° um "fallback" e tentar√° com a temperatura incrementada. O valor tamb√©m varia de `0.0` a `1.0`. No entanto, **cuidado: definir `0.0` para este argumento causar√° um erro `ZeroDivisionError: float division by zero`** (isso pode ser um pequeno "bugzinho" ü´£, mas, de fato, n√£o faria muito sentido usar zero aqui, j√° que o objetivo √© justamente *incrementar* a temperatura). O valor padr√£o √© `0.2`.

---
