# sussu(rro): CLI educacional com OpenAI Whisper

> Ferramenta de linha de comando focada em educa√ß√£o e IA offline.
> Usa o poder do Whisper da OpenAI pra transcrever √°udios e v√≠deos de forma simples.

Ao rodar este projeto, uma das primeiras coisas que voc√™ vai querer fazer √© usar o
comando `whisper` para fazer a transcri√ß√£o inicial de algum v√≠deo ou √°udio. Essa transcri√ß√£o √© um √≥timo jeito de ver na pr√°tica como o Whisper trabalha e o que esperar dos resultados.

Por isso, vamos come√ßar pela **instala√ß√£o** do projeto, o que vai disponibilizar os comandos `sussu` e `whisper` no terminal.

## Instala√ß√£o do `sussu`

Este projeto usa o `Python 3.11.9` por quest√µes de compatibilidade com o Whisper. Evite alterar essa vers√£o caso n√£o saiba o que est√° fazendo, porque eu **j√° testei tudo para voc√™**.

Al√©m disso, este projeto tamb√©m usa o [uv](https://docs.astral.sh/uv/) no gerenciamento geral (pacotes, vers√£o do Python, etc).

```sh
uv sync  # √© s√≥ isso mesmo üòÖ
```

`uv sync` √© suficiente para:

- Baixar e instalar o `python 3.11.9`
- Criar o ambiente virtual em `.venv`
- Instalar os pacotes necess√°rios
- Buildar o `whisper` e o `sussu`

---

## Rodando pela primeira vez

Para testar se tudo funcionou perfeitamente voc√™ pode tanto **ativar o ambiente virtual** quanto usar **`uv run`**. Teste com `whisper -h`. Isso deve mostrar a `help` completa do `whisper`. Exemplos:

```sh
uv run whisper -h
# Ou se estiver com o ambiente virtual ativo
whisper -h
```

**Observa√ß√£o:** alguns editores como VS Code ou Zed, ativam seu ambiente virtual automaticamente ao abrir uma nova inst√¢ncia do terminal se tudo estiver configurado corretamente, basta sair (`exit`) e abrir novamente o terminal.

---
